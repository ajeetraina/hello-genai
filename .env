# Configuration for the LLM service
LLM_BASE_URL=http://host.docker.internal:12434/engines/llama.cpp/v1

# Configuration for the model to use
LLM_MODEL_NAME=ignaciolopezluna020/llama3.2:1b
#LLM_MODEL_NAME=ignaciolopezluna020/deepseek-r1-distill-llama:8B-Q4_K_M